{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1부"
      ],
      "metadata": {
        "id": "3x1nkbEk5dW1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn5eyF9pRty1",
        "outputId": "9e91a106-0a11-4eac-9257-51aca1d18099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ],
      "source": [
        "# pyspark 설치\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Z7R5PhfkRwUm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df = pd.read_csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/titanic_train.csv')"
      ],
      "metadata": {
        "id": "s6VQ8CzhSJWr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spark Session을 시작하기 위해 몇 가지 필드 추가 생성\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "GNCgtoIgSM8Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spark 변수 생성\n",
        "# sparkSession 이름은 practice\n",
        "spark = SparkSession.builder.appName('practice').getOrCreate() "
      ],
      "metadata": {
        "id": "xXQH1kEMSSMu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "UJT91IVoSTrx",
        "outputId": "a5048fd8-95ca-451e-9b23-35307d372e09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://86819e54de5d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f71cd99f390>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test1.csv')"
      ],
      "metadata": {
        "id": "9nBB1GvJSjdi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_pyspark)   # 엑셀의 0행 에 있는 모든 열들을 나타내줌\n",
        "df_pyspark.show()   # dataset보기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax68VPw3irI1",
        "outputId": "b7afb789-6e10-476f-b5be-9357b071f508"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[_c0: string, _c1: string, _c2: string]\n",
            "+---------+---+----------+\n",
            "|      _c0|_c1|       _c2|\n",
            "+---------+---+----------+\n",
            "|     Name|age|Experience|\n",
            "|    Krish| 31|        10|\n",
            "|Sudhanshu| 30|         8|\n",
            "|    Sunny| 29|         4|\n",
            "+---------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Name과 Age를 메인컬럼으로 지정하려면 .option을 설정한다.  \n",
        "# 첫번쨰 행을 header로 간주\n",
        "print( spark.read.option('header','true').csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test1.csv') )\n",
        "df_pyspark = spark.read.option('header','true').csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test1.csv')\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmdcwsvcjdXi",
        "outputId": "87352f98-a94e-49f4-8721-34afe83eee87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[Name: string, age: string, Experience: string]\n",
            "+---------+---+----------+\n",
            "|     Name|age|Experience|\n",
            "+---------+---+----------+\n",
            "|    Krish| 31|        10|\n",
            "|Sudhanshu| 30|         8|\n",
            "|    Sunny| 29|         4|\n",
            "+---------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10gZKqYtkkI_",
        "outputId": "55e12254-e067-4093-9253-5fde1035c06d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)   # pyspark에서 head는 각 행에 대한 정보가 기본적으로 표시됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqbqtW_Tk6o6",
        "outputId": "79b2fa55-15f9-4ee4-985b-2657637d8363"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Krish', age='31', Experience='10'),\n",
              " Row(Name='Sudhanshu', age='30', Experience='8'),\n",
              " Row(Name='Sunny', age='29', Experience='4')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printSchema \n",
        "df_pyspark.printSchema()   # 열 정보를 나타내줌"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqvPNTdTk2gM",
        "outputId": "0ad17042-ee35-4c7a-d7dc-0aa1eb0a35ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기\n",
        "- 데이터 불러오기\n",
        "- 행, 열 정보 확인\n",
        "- dataframe 살펴보기\n"
      ],
      "metadata": {
        "id": "TrH5jemmmL9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pyspark로 작업하기 위해서는 SparkSession을 시작해야한다.\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "Hs4fFKB9laI5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Dataframe').getOrCreate()"
      ],
      "metadata": {
        "id": "u7xBGEJykQZU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "4LHemvjgmnjO",
        "outputId": "858bfbf5-304f-4212-daeb-547203f6b7aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://86819e54de5d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f71cd99f390>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 읽기\n",
        "print( spark.read.option('header','true').csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test1.csv') )\n",
        "spark.read.option('header','true').csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test1.csv').show()\n",
        "df_pyspark.printSchema()  # PrintSchema → 열의 유형 확인\n",
        "\n",
        "# 불러온 dataset을 'df_pyspark'라는 변수에 저장\n",
        "df_pyspark = spark.read.option('header','true').csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z6AXhTumpYw",
        "outputId": "16118fc7-a20e-49cc-f96a-9d13c79183b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[Name: string, age: string, Experience: string]\n",
            "+---------+---+----------+\n",
            "|     Name|age|Experience|\n",
            "+---------+---+----------+\n",
            "|    Krish| 31|        10|\n",
            "|Sudhanshu| 30|         8|\n",
            "|    Sunny| 29|         4|\n",
            "+---------+---+----------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**excel에서는 숫자로 적었는데 왜 문자열로 인식할까?**  \n",
        "  - csv에서 옵션을 지정하지 않는 한 문자열로 인식하는듯하다.\n",
        "\n",
        "**해결 방법**\n",
        "- spark로 csv파일을 읽을 때 csv파일에 `inferSchema=True`옵션을 추가해줘서 의도한대로 data형식이 잘 나오도록 한다."
      ],
      "metadata": {
        "id": "Ndsr4noAonVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.option('header','true').csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test1.csv',inferSchema=True)\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWNOdt3KoSbD",
        "outputId": "b146c612-d9e6-4bee-dd23-33c05c8d89f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# header와 추론 스키마를 모두 포함하도록하는 방법 \n",
        "df_pyspark = spark.read.csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test1.csv',\n",
        "                            header=True,inferSchema=True)\n",
        "print(df_pyspark.printSchema())\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9dU4BmukM4p",
        "outputId": "4002ba56-1f1e-4d9e-9935-8ba2b6ef1e23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            "\n",
            "None\n",
            "+---------+---+----------+\n",
            "|     Name|age|Experience|\n",
            "+---------+---+----------+\n",
            "|    Krish| 31|        10|\n",
            "|Sudhanshu| 30|         8|\n",
            "|    Sunny| 29|         4|\n",
            "+---------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)  # type은 DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnoD1u_sqyRj",
        "outputId": "0eda4a2d-d5d2-4bb4-8343-44779578f843"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2부"
      ],
      "metadata": {
        "id": "SFgiTahg5Xdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 열 선택 & 인덱싱"
      ],
      "metadata": {
        "id": "XQS8lwDNuCl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 열 이름 확인\n",
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPQf-IOnq3C8",
        "outputId": "36572b7e-6d15-48d1-f1b7-18ab00f1ec64"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age', 'Experience']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pandas에서 .head()는 dataframe형태로 확인이 가능했지만 \n",
        "# pyspark에서 .head()는 각 행의 내용을 보여줌 \n",
        "df_pyspark.head(3)  # 각 행 정보 확인 가능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twsyhT28uxhI",
        "outputId": "410474e1-3caa-4b62-8b7b-babb5cfed8ac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Krish', age=31, Experience=10),\n",
              " Row(Name='Sudhanshu', age=30, Experience=8),\n",
              " Row(Name='Sunny', age=29, Experience=4)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igp4-R_EvPA0",
        "outputId": "18254076-5ab3-4b36-cc9c-5926742e8491"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+\n",
            "|     Name|age|Experience|\n",
            "+---------+---+----------+\n",
            "|    Krish| 31|        10|\n",
            "|Sudhanshu| 30|         8|\n",
            "|    Sunny| 29|         4|\n",
            "+---------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 열 선택\n",
        "print( df_pyspark.select('Name') )   # Dataframe 형태로 반환됨\n",
        "print( type(df_pyspark.select('Name')) )\n",
        "\n",
        "# 열을 선택한 뒤 .show()를 해주면 해당하는 열만 보여줌\n",
        "df_pyspark.select('Name').show()     \n",
        "df_pyspark.select('Name','Age').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-jh8tyuuwKM",
        "outputId": "5be65e4e-38f0-418e-e448-d62e6328c61b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[Name: string]\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "+---------+\n",
            "|     Name|\n",
            "+---------+\n",
            "|    Krish|\n",
            "|Sudhanshu|\n",
            "|    Sunny|\n",
            "+---------+\n",
            "\n",
            "+---------+---+\n",
            "|     Name|Age|\n",
            "+---------+---+\n",
            "|    Krish| 31|\n",
            "|Sudhanshu| 30|\n",
            "|    Sunny| 29|\n",
            "+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select('Name','Age').show()\n",
        "# df_pyspark.select(['Name','Age']).show()    # 동일한 결과"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcxs-Vtyv1K2",
        "outputId": "c361262c-7215-419d-af25-cbc048d771ad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+\n",
            "|     Name|Age|\n",
            "+---------+---+\n",
            "|    Krish| 31|\n",
            "|Sudhanshu| 30|\n",
            "|    Sunny| 29|\n",
            "+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pandas에서 열을 직접 선택할 경우\n",
        "df_pyspark['Name']   # 열이 반환됨  → Columns<'Name'>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2mZYp-YwvaY",
        "outputId": "776449fe-7fbb-4b4f-bbb3-2b79c8914e38"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'Name'>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 직접 열을 선택하는 경우에는 .show()를 지원하지 않음\n",
        "# df_pyspark['Name'].show()"
      ],
      "metadata": {
        "id": "jLc3xVw8xISA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형 확인\n",
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujCy19fWzmyU",
        "outputId": "05eb0311-de0e-4d98-cf0e-adace3c13018"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int'), ('Experience', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 설명 \n",
        "print( df_pyspark.describe() )  \n",
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c0cFoqIzv3D",
        "outputId": "a51dd4e3-0afa-4f49-8157-ac1711951cb2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[summary: string, Name: string, age: string, Experience: string]\n",
            "+-------+-----+----+-----------------+\n",
            "|summary| Name| age|       Experience|\n",
            "+-------+-----+----+-----------------+\n",
            "|  count|    3|   3|                3|\n",
            "|   mean| null|30.0|7.333333333333333|\n",
            "| stddev| null| 1.0|3.055050463303893|\n",
            "|    min|Krish|  29|                4|\n",
            "|    max|Sunny|  31|               10|\n",
            "+-------+-----+----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 열 추가"
      ],
      "metadata": {
        "id": "8liSArZU1Y5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 열 추가  \n",
        "# .withColumn은 클래스를 추가하거나 동일한 이름을 가진 기존 열을 교체하여 새 DF를 반환\n",
        "df_pyspark.withColumn('Esperience After 2 Year',df_pyspark['Experience']+2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdSP51ZK0V44",
        "outputId": "962fa2eb-7b0d-46ec-b6b9-3de5144733b9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, age: int, Experience: int, Esperience After 2 Year: int]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.withColumn('Esperience After 2 Year',df_pyspark['Experience']+2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU3Fgoky2cxe",
        "outputId": "e07e05ff-2e19-4bfa-dcb8-f396cf66adf9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+-----------------------+\n",
            "|     Name|age|Experience|Esperience After 2 Year|\n",
            "+---------+---+----------+-----------------------+\n",
            "|    Krish| 31|        10|                     12|\n",
            "|Sudhanshu| 30|         8|                     10|\n",
            "|    Sunny| 29|         4|                      6|\n",
            "+---------+---+----------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 추가한 열이 기존 df에는 추가되지 않음\n",
        "# 저장하기 위해서는 변수에 할당해야함\n",
        "\n",
        "df_pyspark = df_pyspark.withColumn('EXperience After 2 Year',df_pyspark['Experience']+2)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdKgHGQB27Sh",
        "outputId": "9dbf6d54-7d6a-4513-957c-e50e6ec74b2c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+-----------------------+\n",
            "|     Name|age|Experience|EXperience After 2 Year|\n",
            "+---------+---+----------+-----------------------+\n",
            "|    Krish| 31|        10|                     12|\n",
            "|Sudhanshu| 30|         8|                     10|\n",
            "|    Sunny| 29|         4|                      6|\n",
            "+---------+---+----------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 열 삭제"
      ],
      "metadata": {
        "id": "eXWZs3J33JVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns\n",
        "df_pyspark.drop('Experience After 2 Year').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXRyKdJ83IFS",
        "outputId": "f82ebe01-0003-4967-895f-e23cab15a875"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+\n",
            "|     Name|age|Experience|\n",
            "+---------+---+----------+\n",
            "|    Krish| 31|        10|\n",
            "|Sudhanshu| 30|         8|\n",
            "|    Sunny| 29|         4|\n",
            "+---------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop 또한 기존 DF에는 영향을 주지 않음\n",
        "# 변수에 할당해야함\n",
        "df_pyspark = df_pyspark.drop('Experience After 2 Year')"
      ],
      "metadata": {
        "id": "hUDsrcia3RSE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# column명 변경"
      ],
      "metadata": {
        "id": "P6GsgoEE4FTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename columns  - 기존 DF에 영향 X\n",
        "df_pyspark.withColumnRenamed('Name','NEW Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrIPy7PO3uMf",
        "outputId": "17ff115d-7be9-4cbf-a464-99932470a1db"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+\n",
            "| NEW Name|age|Experience|\n",
            "+---------+---+----------+\n",
            "|    Krish| 31|        10|\n",
            "|Sudhanshu| 30|         8|\n",
            "|    Sunny| 29|         4|\n",
            "+---------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = df_pyspark.withColumnRenamed('Name','NEW Name')\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psY-3xR34Wll",
        "outputId": "ca719fd4-9f58-42f7-ceda-e556e9e56ba2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+\n",
            "| NEW Name|age|Experience|\n",
            "+---------+---+----------+\n",
            "|    Krish| 31|        10|\n",
            "|Sudhanshu| 30|         8|\n",
            "|    Sunny| 29|         4|\n",
            "+---------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3부"
      ],
      "metadata": {
        "id": "8n3ahbDx5T4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Null 값 처리\n",
        "- 행, 열 삭제 방법\n",
        "- \n",
        "- 누락된 값을 처리할 떄의 다양한 매개변수"
      ],
      "metadata": {
        "id": "HyUTSipI4q7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('practice').getOrCreate()"
      ],
      "metadata": {
        "id": "7C5yu5Qv4wh-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( spark.read.csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test2.csv',header=True, inferSchema=True) )\n",
        "spark.read.csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test2.csv',header=True, inferSchema=True).show()\n",
        "\n",
        "df_pyspark = spark.read.csv('/content/drive/MyDrive/멀티캠퍼스/DE/data/test2.csv',header=True, inferSchema=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85cbIUPc6rko",
        "outputId": "8325df0d-7c4b-4720-d8aa-6ee30c97cc25"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[Name: string, age: int, Experience: int, Salary: int]\n",
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|SudhanShu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null|  4000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  46|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 열 삭제\n",
        "df_pyspark.drop('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBwl7e6I8BvT",
        "outputId": "0ed8eb7a-ea60-447c-8632-63ed1f4d65d9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+\n",
            "| age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|null|      null|  4000|\n",
            "|  34|        10| 38000|\n",
            "|  46|      null|  null|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 행 삭제"
      ],
      "metadata": {
        "id": "OqPfSJVg-HJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 행 삭제\n",
        "df_pyspark.na.drop().show()  # null값이 들어있는 행 삭제"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hmbzf5m8ZQf",
        "outputId": "160b3db8-8431-44b1-e58a-4776a25d1998"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|SudhanShu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how == all\n",
        "# 모든 컬럼이 null일 경우에만 삭제 \n",
        "df_pyspark.na.drop(how='all').show()\n",
        "\n",
        "# test2.csv와 같은 경우 적어도 하나의 값을 가지고 있기 때문에 삭제되지는 않았음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kwUq7cN8mxw",
        "outputId": "a31aa74d-ee4f-43b1-ca1d-14275dc0e2b1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|SudhanShu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null|  4000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  46|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how == any\n",
        "# 하나라도 null값이 있으면 제거\n",
        "df_pyspark.na.drop(how='any').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twIcVPsh9tBK",
        "outputId": "0bf14985-58be-48ec-dfee-eb80a8ba1260"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|SudhanShu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 임계값"
      ],
      "metadata": {
        "id": "IqLD4YLP-LO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# threshold\n",
        "# thresh 옵션을 이용하여 임계값 설정\n",
        "# null값이 2개가 초과인 행은 제거하도록 함 \n",
        "df_pyspark.na.drop(how='any',thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezgD_OYs-OPO",
        "outputId": "902340ad-6ad3-4df0-c0b3-f08454ce814d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|SudhanShu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null|  4000|\n",
            "|     null|  34|        10| 38000|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## subset"
      ],
      "metadata": {
        "id": "kTEJqX5y_UVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# subset \n",
        "# 특정 열에 대해서 null값이 있는 행 삭제\n",
        "df_pyspark.na.drop(how='any', subset=['Experience']).show()  \n",
        "df_pyspark.na.drop(how='any', subset=['Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2gpqTaL--Jx",
        "outputId": "7d84c608-610d-4ad5-f171-e279b7fbbfb6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|SudhanShu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "+---------+---+----------+------+\n",
            "\n",
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|SudhanShu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "|     null| 46|      null|  null|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Null 값 채우기"
      ],
      "metadata": {
        "id": "uqqUXTyFAQz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 누락된 값 채우기\n",
        "# null 값을 채울 때 채우려는 값의 data type과 컬럼의 data type이 맞아야 함\n",
        " \n",
        "# null 값을 'Missing Values'로 채우기  - Name만 str이므로 Name의 null값만 채워짐\n",
        "print('행 하나 선택')\n",
        "df_pyspark.na.fill('Missing Values').show() \n",
        "\n",
        "# 여러 행을 선택하는 것도 가능\n",
        "print('행 다중 선택')\n",
        "df_pyspark.na.fill(0,['Age','Salary']).show()\n",
        "\n",
        "# 지정도 가능\n",
        "print('채우고자 하는 행 지정')\n",
        "df_pyspark.na.fill( {'Name':'Missing Values', 'Salary' : '0'} ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZQubU4CAWpK",
        "outputId": "23a84f24-c4d3-4e78-cb2a-3968e23aa767"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "행 하나 선택\n",
            "+--------------+----+----------+------+\n",
            "|          Name| age|Experience|Salary|\n",
            "+--------------+----+----------+------+\n",
            "|         Krish|  31|        10| 30000|\n",
            "|     SudhanShu|  30|         8| 25000|\n",
            "|         Sunny|  29|         4| 20000|\n",
            "|          Paul|  24|         3| 20000|\n",
            "|        Harsha|  21|         1| 15000|\n",
            "|       Shubham|  23|         2| 18000|\n",
            "|        Mahesh|null|      null|  4000|\n",
            "|Missing Values|  34|        10| 38000|\n",
            "|Missing Values|  46|      null|  null|\n",
            "+--------------+----+----------+------+\n",
            "\n",
            "행 다중 선택\n",
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|SudhanShu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|   Mahesh|  0|      null|  4000|\n",
            "|     null| 34|        10| 38000|\n",
            "|     null| 46|      null|     0|\n",
            "+---------+---+----------+------+\n",
            "\n",
            "채우고자 하는 행 지정\n",
            "+--------------+----+----------+------+\n",
            "|          Name| age|Experience|Salary|\n",
            "+--------------+----+----------+------+\n",
            "|         Krish|  31|        10| 30000|\n",
            "|     SudhanShu|  30|         8| 25000|\n",
            "|         Sunny|  29|         4| 20000|\n",
            "|          Paul|  24|         3| 20000|\n",
            "|        Harsha|  21|         1| 15000|\n",
            "|       Shubham|  23|         2| 18000|\n",
            "|        Mahesh|null|      null|  4000|\n",
            "|Missing Values|  34|        10| 38000|\n",
            "|Missing Values|  46|      null|     0|\n",
            "+--------------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Null 값을 평균으로 대체\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['age','Experience','Salary'],\n",
        "    outputCols = [f'{c}_imputed' for c in ['age','Experience','Salary']]\n",
        "    ).setStrategy(\"mean\")   # 평균값으로 채우겠다고 설정\n",
        "\n",
        " # 중앙값은 'median'   "
      ],
      "metadata": {
        "id": "_8XAj4SzCjCU"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'imputer'라는 행 추가..?\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lD-XKPxERhP",
        "outputId": "c60dbe6a-9a80-455d-e461-a4b3d986fe04"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|SudhanShu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|null|      null|  4000|         29|                 5|          4000|\n",
            "|     null|  34|        10| 38000|         34|                10|         38000|\n",
            "|     null|  46|      null|  null|         46|                 5|         21250|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "45분"
      ],
      "metadata": {
        "id": "xGS5jVPqHuOC"
      }
    }
  ]
}